{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Generalized Shapley Additive Explanations Generalized Shapley Additive Explanations (G-SHAP) is a technique in explainable AI for answering broad questions in machine learning. Applications This is just a small sample of the questions G-SHAP can answer. General classification and regression Suppose we have a black-box model which diagnoses patients with COVID-19, the flu, or a common cold based on their symptoms. Existing explanatory methods can tell us why our model diagnosed a patient with COVID-19. G-SHAP can answer broader questions, such as how do the symptoms which distinguish COVID-19 from the flu differ from those which distinguish COVID-19 from the common cold? . Full analysis here . Intergroup differences Suppose we have a black-box model which predicts a criminal\u2019s risk of recidivism to determine whether they are eligible for parole. Existing explanatory methods can tell us why our model predicted that a criminal has a high recidivism risk. G-SHAP can answer broader questions, such as why does our model predict that Black criminals have higher recidivism rates than White criminals? . Full analysis here . Model performance and failure Suppose we have a black-box model which forecasts GDP growth based on macroeconomic variables. Existing explanatory methods can tell us why our model forecast 3% GDP growth in a given year. G-SHAP can answer broader questions, such as why did our model fail to forecast the 2008-2009 financial crisis? . Full analysis here . Installation $ pip install gshap Quickstart Here we train a support vector classifier to predict whether a criminal will recidivate within two years of release from prison. We use G-SHAP to ask why our model predicts that Black criminals are more likely to recidivate than non-Black criminals. import gshap from gshap.datasets import load_recidivism from gshap.intergroup import IntergroupDifference from sklearn.svm import SVC recidivism = load_recidivism() X, y = recidivism.data, recidivism.target clf = SVC().fit(X, y) g = IntergroupDifference(group=X['black'], distance='relative_mean_distance') explainer = gshap.KernelExplainer(clf.predict, X, g) explainer.gshap_values(X, nsamples=10) Out: array([ 0.01335252, 0.24884556, 0.00132373, -0.0025238 , -0.00151837, 0.40453822, 0.01636782, 0.07666043, -0.00056414, 0.00966583]) The sum of the G-SHAP values is the relative difference in predicted recidivism rates. The model predicts that Black criminals are 75% more likely to recidivate. The variables most responsible for this difference are number of prior convictions (index 5; 40%), age (index 1; 25%), and race (index 7; 8%). Citation @software{bowen2020gshap, author = {Dillon Bowen}, title = {Generalized Shapley Additive Explanations}, url = {https://dsbowen.github.io/gshap/}, date = {2020-05-19}, } License Users must cite G-SHAP in any publications which use this software. G-SHAP is licensed with the MIT License .","title":"Home"},{"location":"#generalized-shapley-additive-explanations","text":"Generalized Shapley Additive Explanations (G-SHAP) is a technique in explainable AI for answering broad questions in machine learning.","title":"Generalized Shapley Additive Explanations"},{"location":"#applications","text":"This is just a small sample of the questions G-SHAP can answer.","title":"Applications"},{"location":"#general-classification-and-regression","text":"Suppose we have a black-box model which diagnoses patients with COVID-19, the flu, or a common cold based on their symptoms. Existing explanatory methods can tell us why our model diagnosed a patient with COVID-19. G-SHAP can answer broader questions, such as how do the symptoms which distinguish COVID-19 from the flu differ from those which distinguish COVID-19 from the common cold? . Full analysis here .","title":"General classification and regression"},{"location":"#intergroup-differences","text":"Suppose we have a black-box model which predicts a criminal\u2019s risk of recidivism to determine whether they are eligible for parole. Existing explanatory methods can tell us why our model predicted that a criminal has a high recidivism risk. G-SHAP can answer broader questions, such as why does our model predict that Black criminals have higher recidivism rates than White criminals? . Full analysis here .","title":"Intergroup differences"},{"location":"#model-performance-and-failure","text":"Suppose we have a black-box model which forecasts GDP growth based on macroeconomic variables. Existing explanatory methods can tell us why our model forecast 3% GDP growth in a given year. G-SHAP can answer broader questions, such as why did our model fail to forecast the 2008-2009 financial crisis? . Full analysis here .","title":"Model performance and failure"},{"location":"#installation","text":"$ pip install gshap","title":"Installation"},{"location":"#quickstart","text":"Here we train a support vector classifier to predict whether a criminal will recidivate within two years of release from prison. We use G-SHAP to ask why our model predicts that Black criminals are more likely to recidivate than non-Black criminals. import gshap from gshap.datasets import load_recidivism from gshap.intergroup import IntergroupDifference from sklearn.svm import SVC recidivism = load_recidivism() X, y = recidivism.data, recidivism.target clf = SVC().fit(X, y) g = IntergroupDifference(group=X['black'], distance='relative_mean_distance') explainer = gshap.KernelExplainer(clf.predict, X, g) explainer.gshap_values(X, nsamples=10) Out: array([ 0.01335252, 0.24884556, 0.00132373, -0.0025238 , -0.00151837, 0.40453822, 0.01636782, 0.07666043, -0.00056414, 0.00966583]) The sum of the G-SHAP values is the relative difference in predicted recidivism rates. The model predicts that Black criminals are 75% more likely to recidivate. The variables most responsible for this difference are number of prior convictions (index 5; 40%), age (index 1; 25%), and race (index 7; 8%).","title":"Quickstart"},{"location":"#citation","text":"@software{bowen2020gshap, author = {Dillon Bowen}, title = {Generalized Shapley Additive Explanations}, url = {https://dsbowen.github.io/gshap/}, date = {2020-05-19}, }","title":"Citation"},{"location":"#license","text":"Users must cite G-SHAP in any publications which use this software. G-SHAP is licensed with the MIT License .","title":"License"},{"location":"contribute/","text":"Contribute to G-SHAP I encourage users to contribute, including: Optimized methods for computing or approximating G-SHAP values. Additional general functions.","title":"Contribute"},{"location":"contribute/#contribute-to-g-shap","text":"I encourage users to contribute, including: Optimized methods for computing or approximating G-SHAP values. Additional general functions.","title":"Contribute to G-SHAP"},{"location":"datasets/","text":"a.src-href { float: right; } p.attr { margin-top: 0.5em; margin-left: 1em; } p.func-header { background-color: gainsboro; border-radius: 0.1em; padding: 0.5em; padding-left: 1em; } table.field-table { border-radius: 0.1em } Example datasets gshap.datasets. load_recidivism def gshap.datasets. load_recidivism ( return_X_y=False ) [source] Load the COMPAS recidivism dataset. The purpose of this dataset is to predict whether a criminal will recidivate within two years of release. Parameters: return_X_y : bool, default=False Indicates whether to return just the X and y matrices, as opposed to the data Bunch . Returns: bunch : Bunch Object containing the dataframe, X feature matrix, and y target vector. Or, if return_X_y , return (X,y). gshap.datasets. load_gdp def gshap.datasets. load_gdp ( return_X_y=False ) [source] Load the GDP growth dataset (from FRED data). The purpose of this dataset is to forecast GDP growth based on macroeconomic variables. Parameters: return_X_y : bool, default=False Indicates whether to return just the X and y matrices, as opposed to the data Bunch . Returns: bunch : Bunch Object containing the dataframe, X feature matrix, and y target vector. Or, if return_X_y , return (X,y). gshap.datasets. Bunch class gshap.datasets. Bunch ( filename, target ) [source] Dataset container. Parameters: filename : str Name of the file in gshap/datasets . target : str Name of target variable Attributes: df : pandas.DataFrame Dataframe containing features and the target variable. data : pandas.DataFrame Dataframe containing only the features target : pandas.Series Series of the target variable.","title":"Datasets"},{"location":"datasets/#example-datasets","text":"","title":"Example datasets"},{"location":"datasets/#gshapdatasetsload_recidivism","text":"def gshap.datasets. load_recidivism ( return_X_y=False ) [source] Load the COMPAS recidivism dataset. The purpose of this dataset is to predict whether a criminal will recidivate within two years of release. Parameters: return_X_y : bool, default=False Indicates whether to return just the X and y matrices, as opposed to the data Bunch . Returns: bunch : Bunch Object containing the dataframe, X feature matrix, and y target vector. Or, if return_X_y , return (X,y).","title":"gshap.datasets.load_recidivism"},{"location":"datasets/#gshapdatasetsload_gdp","text":"def gshap.datasets. load_gdp ( return_X_y=False ) [source] Load the GDP growth dataset (from FRED data). The purpose of this dataset is to forecast GDP growth based on macroeconomic variables. Parameters: return_X_y : bool, default=False Indicates whether to return just the X and y matrices, as opposed to the data Bunch . Returns: bunch : Bunch Object containing the dataframe, X feature matrix, and y target vector. Or, if return_X_y , return (X,y).","title":"gshap.datasets.load_gdp"},{"location":"datasets/#gshapdatasetsbunch","text":"class gshap.datasets. Bunch ( filename, target ) [source] Dataset container. Parameters: filename : str Name of the file in gshap/datasets . target : str Name of target variable Attributes: df : pandas.DataFrame Dataframe containing features and the target variable. data : pandas.DataFrame Dataframe containing only the features target : pandas.Series Series of the target variable.","title":"gshap.datasets.Bunch"},{"location":"hypothesis/","text":"a.src-href { float: right; } p.attr { margin-top: 0.5em; margin-left: 1em; } p.func-header { background-color: gainsboro; border-radius: 0.1em; padding: 0.5em; padding-left: 1em; } table.field-table { border-radius: 0.1em } Hypothesis testing For examples and interpretation, see my notebook on hypothesis test explanations . gshap.hypothesis. HypothesisTest class gshap.hypothesis. HypothesisTest ( test, bootstrap_samples=1000 ) [source] This class measures how likely a hypothesis is to be true of an output vector. It uses a bootstrap analysis to compute the probability that a hypothesis is true of a population from a sample output vector. Parameters: test : callable Takes an output vector and returns a boolean indicator that the hypothesis is true of the output vector. This will usually involve computing a sample statistic of the output vector, then returning an indicator that the sample statistic fell within a certain range. bootstrap_samples : int Number of bootstrap samples for hypothesis testing. Attributes: test : callable Set from the test parameter. bootstrap_samples : int Set from the bootstrap_samples parameter. Examples import gshap from gshap.hypothesis import HypothesisTest from sklearn.datasets import load_diabetes from sklearn.linear_model import Lasso X, y = load_diabetes(return_X_y=True) reg = Lasso(alpha=.1).fit(X, y) test = lambda y_pred: y_pred.mean() > 155 g = HypothesisTest(test, bootstrap_samples=100) explainer = gshap.KernelExplainer(reg.predict, X, g) # artifically select a sample which with higher-than-average y explainer.gshap_values(X[y > 70], nsamples=100) Out: array([-0.0069, 0.0253, 0.2572, 0.1112, -0.0108, -0.0105, 0.0317, 0.0009, 0.1415, 0.0071]) Methods __call__ ( self, output ) [source] Computes the probablity of the hypothesis being true of the population from which the sample was drawn. Parameters: output : numpy.array (# observations, # targets) vector of model outputs. Returns: probability : scalar between 0 and 1 Probability that the hypothesis is true of the population from which the sample was drawn.","title":"Hypothesis testing"},{"location":"hypothesis/#hypothesis-testing","text":"For examples and interpretation, see my notebook on hypothesis test explanations .","title":"Hypothesis testing"},{"location":"hypothesis/#gshaphypothesishypothesistest","text":"class gshap.hypothesis. HypothesisTest ( test, bootstrap_samples=1000 ) [source] This class measures how likely a hypothesis is to be true of an output vector. It uses a bootstrap analysis to compute the probability that a hypothesis is true of a population from a sample output vector. Parameters: test : callable Takes an output vector and returns a boolean indicator that the hypothesis is true of the output vector. This will usually involve computing a sample statistic of the output vector, then returning an indicator that the sample statistic fell within a certain range. bootstrap_samples : int Number of bootstrap samples for hypothesis testing. Attributes: test : callable Set from the test parameter. bootstrap_samples : int Set from the bootstrap_samples parameter.","title":"gshap.hypothesis.HypothesisTest"},{"location":"hypothesis/#examples","text":"import gshap from gshap.hypothesis import HypothesisTest from sklearn.datasets import load_diabetes from sklearn.linear_model import Lasso X, y = load_diabetes(return_X_y=True) reg = Lasso(alpha=.1).fit(X, y) test = lambda y_pred: y_pred.mean() > 155 g = HypothesisTest(test, bootstrap_samples=100) explainer = gshap.KernelExplainer(reg.predict, X, g) # artifically select a sample which with higher-than-average y explainer.gshap_values(X[y > 70], nsamples=100) Out: array([-0.0069, 0.0253, 0.2572, 0.1112, -0.0108, -0.0105, 0.0317, 0.0009, 0.1415, 0.0071])","title":"Examples"},{"location":"hypothesis/#methods","text":"__call__ ( self, output ) [source] Computes the probablity of the hypothesis being true of the population from which the sample was drawn. Parameters: output : numpy.array (# observations, # targets) vector of model outputs. Returns: probability : scalar between 0 and 1 Probability that the hypothesis is true of the population from which the sample was drawn.","title":"Methods"},{"location":"intergroup/","text":"a.src-href { float: right; } p.attr { margin-top: 0.5em; margin-left: 1em; } p.func-header { background-color: gainsboro; border-radius: 0.1em; padding: 0.5em; padding-left: 1em; } table.field-table { border-radius: 0.1em } Intergroup differences For examples and interpretation, see my notebook on intergroup difference explanations . gshap.intergroup. IntergroupDifference class gshap.intergroup. IntergroupDifference ( group, distance='absolute_mean_distance' ) [source] This class measures the distance between distributions of predicted outcomes for different groups. Paramters: group : numpy.array or pandas.Series (# observations,) array of boolean or binary values indicating group membership. distance : callable or str, default='absolute_mean_distance' Takes two vectors of model output for the outgroup and ingroup. Output vectors will usually be (# outgroup,) and (# ingroup,), or (# outgroup, # classes) and (# ingroup, # classes). distance returns a scalar measure of intergroup difference, such as the absolute difference between group means. If input as a string, distance is used as a key to look up built-in distance functions. Attributes: group : numpy.array Set from the group parameter. If the parameter is passed as a pandas.Series , it is automatically converted in a numpy.array . distance : callable or str Set from the distance parameter. Examples import gshap from gshap.datasets import load_recidivism from gshap.intergroup import IntergroupDifference from sklearn.svm import SVC recidivism = load_recidivism() X, y = recidivism.data, recidivism.target clf = SVC().fit(X,y) g = IntergroupDifference(group=X['black'], distance='relative_mean_distance') explainer = gshap.KernelExplainer(clf.predict, X, g) explainer.gshap_values(X, nsamples=10) Out: array([ 0.01335252, 0.24884556, 0.00132373, -0.0025238 , -0.00151837, 0.40453822, 0.01636782, 0.07666043, -0.00056414, 0.00966583]) Methods __call__ ( self, output ) [source] Compute distance measure between groups. Parameters: ouput : numpy.array or pandas.Series Model output, usually a (# observations,) or (# observations, # classes) vector. Returns: distance : scalar Measure of the distance between the distributions of predicted outputs for outgroup and ingroup observations. gshap.intergroup. absolute_mean_distance def gshap.intergroup. absolute_mean_distance ( out_0, out_1 ) [source] Parameters: out_0 : np.array (# observations,) vector of model outputs for outgroup observations. out_1 : np.array (# observations,) vector of model outputs for ingroup observations. Returns: distance : scalar out_1.mean() - out_0.mean() gshap.intergroup. relative_mean_distance def gshap.intergroup. relative_mean_distance ( out_0, out_1 ) [source] Parameters: out_0 : np.array (# observations,) vector of model outputs for outgroup observations. out_1 : np.array (# observations,) vector of model outputs for ingroup observations. Returns: distance : scalar out_1.mean() / out_0.mean() - 1","title":"Intergroup differences"},{"location":"intergroup/#intergroup-differences","text":"For examples and interpretation, see my notebook on intergroup difference explanations .","title":"Intergroup differences"},{"location":"intergroup/#gshapintergroupintergroupdifference","text":"class gshap.intergroup. IntergroupDifference ( group, distance='absolute_mean_distance' ) [source] This class measures the distance between distributions of predicted outcomes for different groups. Paramters: group : numpy.array or pandas.Series (# observations,) array of boolean or binary values indicating group membership. distance : callable or str, default='absolute_mean_distance' Takes two vectors of model output for the outgroup and ingroup. Output vectors will usually be (# outgroup,) and (# ingroup,), or (# outgroup, # classes) and (# ingroup, # classes). distance returns a scalar measure of intergroup difference, such as the absolute difference between group means. If input as a string, distance is used as a key to look up built-in distance functions. Attributes: group : numpy.array Set from the group parameter. If the parameter is passed as a pandas.Series , it is automatically converted in a numpy.array . distance : callable or str Set from the distance parameter.","title":"gshap.intergroup.IntergroupDifference"},{"location":"intergroup/#examples","text":"import gshap from gshap.datasets import load_recidivism from gshap.intergroup import IntergroupDifference from sklearn.svm import SVC recidivism = load_recidivism() X, y = recidivism.data, recidivism.target clf = SVC().fit(X,y) g = IntergroupDifference(group=X['black'], distance='relative_mean_distance') explainer = gshap.KernelExplainer(clf.predict, X, g) explainer.gshap_values(X, nsamples=10) Out: array([ 0.01335252, 0.24884556, 0.00132373, -0.0025238 , -0.00151837, 0.40453822, 0.01636782, 0.07666043, -0.00056414, 0.00966583])","title":"Examples"},{"location":"intergroup/#methods","text":"__call__ ( self, output ) [source] Compute distance measure between groups. Parameters: ouput : numpy.array or pandas.Series Model output, usually a (# observations,) or (# observations, # classes) vector. Returns: distance : scalar Measure of the distance between the distributions of predicted outputs for outgroup and ingroup observations.","title":"Methods"},{"location":"intergroup/#gshapintergroupabsolute_mean_distance","text":"def gshap.intergroup. absolute_mean_distance ( out_0, out_1 ) [source] Parameters: out_0 : np.array (# observations,) vector of model outputs for outgroup observations. out_1 : np.array (# observations,) vector of model outputs for ingroup observations. Returns: distance : scalar out_1.mean() - out_0.mean()","title":"gshap.intergroup.absolute_mean_distance"},{"location":"intergroup/#gshapintergrouprelative_mean_distance","text":"def gshap.intergroup. relative_mean_distance ( out_0, out_1 ) [source] Parameters: out_0 : np.array (# observations,) vector of model outputs for outgroup observations. out_1 : np.array (# observations,) vector of model outputs for ingroup observations. Returns: distance : scalar out_1.mean() / out_0.mean() - 1","title":"gshap.intergroup.relative_mean_distance"},{"location":"kernel_explainer/","text":"a.src-href { float: right; } p.attr { margin-top: 0.5em; margin-left: 1em; } p.func-header { background-color: gainsboro; border-radius: 0.1em; padding: 0.5em; padding-left: 1em; } table.field-table { border-radius: 0.1em } Kernel Explainer gshap. KernelExplainer class gshap. KernelExplainer ( model, data, g=lambda x: x.mean() ) [source] The Kernel Explainer is a model-agnostic method of approximating G-SHAP values. Parameters: model : callable Callable which takes a (# observations, # features) matrix and returns an output which will be fed into g . For ordinary SHAP, the model returns a (# observations, # targets) output vector. data : numpy.array or pandas.DataFrame or pandas.Series Background dataset from which values are randomly sampled to simulate absent features. g : callable Callable which takes the model output and returns a scalar. Attributes: model : callable Set from the model parameter. data : numpy.array Set from the data parameter. If data is a pandas object, it is automatically converted to a numpy.array . g : callable Set from the g parameter. Examples This example shows how to compute classical SHAP values. import gshap from sklearn.datasets import load_boston from sklearn.linear_model import LinearRegression X, y = load_boston(return_X_y=True) reg = LinearRegression().fit(X,y) explainer = gshap.KernelExplainer( model=reg.predict, data=X, g=lambda x: x.mean() ) explainer.gshap_values(X, nssamples=1000) Out: array([-8.52873964e-04, -4.90442234e-04, 9.42836482e-05, 3.98231297e-04, 2.03149964e-03, 3.93086231e-03, -7.38176865e-06, 3.81400727e-03, 5.19437337e-03, -1.34661588e-03, 7.08535145e-04, 1.50486721e-03, -8.28480438e-03]) As expected, all SHAP values are 0 for linear regression. We can see this when we compare the mean prediction for the original data X to the shuffled background data explainer.data . explainer.compare(X, bootstrap_samples=1000) Out: 22.53280632411067, 22.52089950825812 Methods compare ( self, X, bootstrap_samples=1000 ) [source] Compares the background data self.data to the comparison data X in terms of the general function self.g . Parameters: X : numpy.array or pandas.Series or pandas.DataFrame (# samples, # features) matrix of comparison data. bootstrap_samples : scalar Number of bootstrapped samples for computing g of the background data. Returns: g_comparison : float g(model(X)) , where X is the comparison data. g_background : float g(model(X_b)) , where X_b is the shuffled background data. gshap_values ( self, X, **kwargs ) [source] Compute G-SHAP values for all features. Parameters: X : numpy.array or pandas.DataFrame or pandas.Series A (# samples, # features) matrix. nsamples : scalar or 'auto', default='auto' Number of samples to draw when approximating G-SHAP values. Returns: gshap_values : np.array (# features,) vector of G-SHAP values ordered by feature index. gshap_value ( self, j, X, **kwargs ) [source] Compute the G-SHAP value for feature j . Parameters: j : scalar or column name The index or column name of the feature of interest. X : numpy.array or pandas.DataFrame or pandas.Series A (# samples, # features) matrix. nsamples : scalar or 'auto', default='auto' Number of samples to draw when approximating G-SHAP values. Returns: gshap_value : float Approximated G-SHAP value for feature j (float).","title":"Kernel explainer"},{"location":"kernel_explainer/#kernel-explainer","text":"","title":"Kernel Explainer"},{"location":"kernel_explainer/#gshapkernelexplainer","text":"class gshap. KernelExplainer ( model, data, g=lambda x: x.mean() ) [source] The Kernel Explainer is a model-agnostic method of approximating G-SHAP values. Parameters: model : callable Callable which takes a (# observations, # features) matrix and returns an output which will be fed into g . For ordinary SHAP, the model returns a (# observations, # targets) output vector. data : numpy.array or pandas.DataFrame or pandas.Series Background dataset from which values are randomly sampled to simulate absent features. g : callable Callable which takes the model output and returns a scalar. Attributes: model : callable Set from the model parameter. data : numpy.array Set from the data parameter. If data is a pandas object, it is automatically converted to a numpy.array . g : callable Set from the g parameter.","title":"gshap.KernelExplainer"},{"location":"kernel_explainer/#examples","text":"This example shows how to compute classical SHAP values. import gshap from sklearn.datasets import load_boston from sklearn.linear_model import LinearRegression X, y = load_boston(return_X_y=True) reg = LinearRegression().fit(X,y) explainer = gshap.KernelExplainer( model=reg.predict, data=X, g=lambda x: x.mean() ) explainer.gshap_values(X, nssamples=1000) Out: array([-8.52873964e-04, -4.90442234e-04, 9.42836482e-05, 3.98231297e-04, 2.03149964e-03, 3.93086231e-03, -7.38176865e-06, 3.81400727e-03, 5.19437337e-03, -1.34661588e-03, 7.08535145e-04, 1.50486721e-03, -8.28480438e-03]) As expected, all SHAP values are 0 for linear regression. We can see this when we compare the mean prediction for the original data X to the shuffled background data explainer.data . explainer.compare(X, bootstrap_samples=1000) Out: 22.53280632411067, 22.52089950825812","title":"Examples"},{"location":"kernel_explainer/#methods","text":"compare ( self, X, bootstrap_samples=1000 ) [source] Compares the background data self.data to the comparison data X in terms of the general function self.g . Parameters: X : numpy.array or pandas.Series or pandas.DataFrame (# samples, # features) matrix of comparison data. bootstrap_samples : scalar Number of bootstrapped samples for computing g of the background data. Returns: g_comparison : float g(model(X)) , where X is the comparison data. g_background : float g(model(X_b)) , where X_b is the shuffled background data. gshap_values ( self, X, **kwargs ) [source] Compute G-SHAP values for all features. Parameters: X : numpy.array or pandas.DataFrame or pandas.Series A (# samples, # features) matrix. nsamples : scalar or 'auto', default='auto' Number of samples to draw when approximating G-SHAP values. Returns: gshap_values : np.array (# features,) vector of G-SHAP values ordered by feature index. gshap_value ( self, j, X, **kwargs ) [source] Compute the G-SHAP value for feature j . Parameters: j : scalar or column name The index or column name of the feature of interest. X : numpy.array or pandas.DataFrame or pandas.Series A (# samples, # features) matrix. nsamples : scalar or 'auto', default='auto' Number of samples to draw when approximating G-SHAP values. Returns: gshap_value : float Approximated G-SHAP value for feature j (float).","title":"Methods"},{"location":"probability_distance/","text":"a.src-href { float: right; } p.attr { margin-top: 0.5em; margin-left: 1em; } p.func-header { background-color: gainsboro; border-radius: 0.1em; padding: 0.5em; padding-left: 1em; } table.field-table { border-radius: 0.1em } General classification and regression explanations For examples and interpretation, see my notebooks on general classification explanations and general regression explanations . gshap.probability_distance. ProbabilityDistance class gshap.probability_distance. ProbabilityDistance ( positive, negative=None ) [source] This class measures how likely each predicted target value (output) was to have been generated by a 'positive' distribution or density, rather than a 'negative' distribution or density. Parameters: positive : callable or list of callables Densities and distributions take the output of a model, usually a (# observations,) or (# observations, # classes) vector. It returns a (# observations,) vector of probabilities that the predicted target value was generated by the density or distribution. negative : callable or list of callables or None, default=None Similarly defined. If None , the probability that each observation comes from a negative density or distribution will be treated as the complement of positive . Attributes: positive : callable or list of callables Set from the positive parameter. negative : callable or list of callables Set from the negative parameter. Examples import gshap from gshap.probability_distance import ProbabilityDistance from sklearn.datasets import load_iris from sklearn.svm import SVC X, y = load_iris(return_X_y=True) clf = SVC(probability=True).fit(X,y) # probability that each observation is in class 1 pos_distribution = lambda y_pred: y_pred[:,1] # probability that each observation is in class 0 neg_distribution = lambda y_pred: y_pred[:,0] g = ProbabilityDistance(pos_distribution, neg_distribution) explainer = gshap.KernelExplainer(clf.predict_proba, X, g) explainer.gshap_values(x, nsamples=1000) Out: array([0.02175944, 0.01505252, 0.17106646, 0.13605429]) Methods __call__ ( self, output ) [source] Parameters: output : np.array Model output, usually (# observations,) or (# obervations, # classes) array for regression or classification problems, respectively. Returns: probability : float Probability that every predicted target value was generated by a positive density or distribution, rather than a negative density or distribution.","title":"General classification and regression"},{"location":"probability_distance/#general-classification-and-regression-explanations","text":"For examples and interpretation, see my notebooks on general classification explanations and general regression explanations .","title":"General classification and regression explanations"},{"location":"probability_distance/#gshapprobability_distanceprobabilitydistance","text":"class gshap.probability_distance. ProbabilityDistance ( positive, negative=None ) [source] This class measures how likely each predicted target value (output) was to have been generated by a 'positive' distribution or density, rather than a 'negative' distribution or density. Parameters: positive : callable or list of callables Densities and distributions take the output of a model, usually a (# observations,) or (# observations, # classes) vector. It returns a (# observations,) vector of probabilities that the predicted target value was generated by the density or distribution. negative : callable or list of callables or None, default=None Similarly defined. If None , the probability that each observation comes from a negative density or distribution will be treated as the complement of positive . Attributes: positive : callable or list of callables Set from the positive parameter. negative : callable or list of callables Set from the negative parameter.","title":"gshap.probability_distance.ProbabilityDistance"},{"location":"probability_distance/#examples","text":"import gshap from gshap.probability_distance import ProbabilityDistance from sklearn.datasets import load_iris from sklearn.svm import SVC X, y = load_iris(return_X_y=True) clf = SVC(probability=True).fit(X,y) # probability that each observation is in class 1 pos_distribution = lambda y_pred: y_pred[:,1] # probability that each observation is in class 0 neg_distribution = lambda y_pred: y_pred[:,0] g = ProbabilityDistance(pos_distribution, neg_distribution) explainer = gshap.KernelExplainer(clf.predict_proba, X, g) explainer.gshap_values(x, nsamples=1000) Out: array([0.02175944, 0.01505252, 0.17106646, 0.13605429])","title":"Examples"},{"location":"probability_distance/#methods","text":"__call__ ( self, output ) [source] Parameters: output : np.array Model output, usually (# observations,) or (# obervations, # classes) array for regression or classification problems, respectively. Returns: probability : float Probability that every predicted target value was generated by a positive density or distribution, rather than a negative density or distribution.","title":"Methods"},{"location":"technical/","text":"Technical details Shapley Additive Explanations (SHAP) measure how important input features are in determining a model's output. The importance of feature j for model f , \\phi_j(f) , is a weighted sum of the feature's contribution to the model's output f(x) over all possible feature combinations: \\phi_j(f) = \\sum_{S\\subseteq \\{x_1,...,x_p\\}\\setminus\\{x_j\\}} \\frac{|S|!(p-|S|-1)!}{p!}\\big(f(S\\cup \\{x_j\\})-f(S)\\big) Where S is a subset of features and p is the number of features in the model. In practice, f(S) is estimated by randomly substituting in values for the remaining features, \\{x_1,\u2026,x_p\\}\\setminus S , from a shuffled background dataset X_b . Suppose we compute the model output for an observation f(x) and the background dataset f(X_b) . Each SHAP value \\phi_j is the amount of this difference f(x)-f(X_b) due to feature j . We can generalize SHAP to compute feature importance for any function g of the model's output. Define a G-SHAP \\phi_j^g(f) value as: \\phi_j^g(f) = \\sum_{S\\subseteq \\{x_1,...,x_p\\}\\setminus\\{x_j\\}} \\frac{|S|!(p-|S|-1)!}{p!}\\big(g(f(S\\cup \\{x_j\\}))-g(f(S))\\big) G-SHAP values have similar interpretation. Suppose we compute a general function of a model\u2019s output for a sample g(f(x)) and for the shuffled background dataset g(f(X_b)) . Each G-SHAP value \\phi_j^g is the amount of this difference g(f(x))-g(f(X_b)) due to feature j .","title":"Technical"},{"location":"technical/#technical-details","text":"Shapley Additive Explanations (SHAP) measure how important input features are in determining a model's output. The importance of feature j for model f , \\phi_j(f) , is a weighted sum of the feature's contribution to the model's output f(x) over all possible feature combinations: \\phi_j(f) = \\sum_{S\\subseteq \\{x_1,...,x_p\\}\\setminus\\{x_j\\}} \\frac{|S|!(p-|S|-1)!}{p!}\\big(f(S\\cup \\{x_j\\})-f(S)\\big) Where S is a subset of features and p is the number of features in the model. In practice, f(S) is estimated by randomly substituting in values for the remaining features, \\{x_1,\u2026,x_p\\}\\setminus S , from a shuffled background dataset X_b . Suppose we compute the model output for an observation f(x) and the background dataset f(X_b) . Each SHAP value \\phi_j is the amount of this difference f(x)-f(X_b) due to feature j . We can generalize SHAP to compute feature importance for any function g of the model's output. Define a G-SHAP \\phi_j^g(f) value as: \\phi_j^g(f) = \\sum_{S\\subseteq \\{x_1,...,x_p\\}\\setminus\\{x_j\\}} \\frac{|S|!(p-|S|-1)!}{p!}\\big(g(f(S\\cup \\{x_j\\}))-g(f(S))\\big) G-SHAP values have similar interpretation. Suppose we compute a general function of a model\u2019s output for a sample g(f(x)) and for the shuffled background dataset g(f(X_b)) . Each G-SHAP value \\phi_j^g is the amount of this difference g(f(x))-g(f(X_b)) due to feature j .","title":"Technical details"}]}